{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "from pytube import Playlist\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import bleach\n",
    "import re\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "from gensim.summarization import keywords\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a,b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(url):\n",
    "    path=url\n",
    "    try:\n",
    "        yt = YouTube(path)\n",
    "    except ValueError:\n",
    "        print('cannot find video')\n",
    "    caption = yt.captions.get_by_language_code('en')\n",
    "    try:\n",
    "        xml=caption.xml_captions\n",
    "    except AttributeError:\n",
    "        print('no captions or transcripts')\n",
    "\n",
    "    root = ET.fromstring(xml)\n",
    "    #gets the transcripts\n",
    "    doc=''\n",
    "    for child in root:\n",
    "        try:\n",
    "            doc=doc+\" \"+(child.text)\n",
    "        except TypeError:\n",
    "            pass\n",
    "    return doc.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corpus(url_list):\n",
    "    corpus=[]\n",
    "    for url in url_list:\n",
    "        x=bleach.clean(get_transcript(url), tags=[], attributes={}, styles=[], strip=True)\n",
    "        y=re.sub(r'&#39;', '', x)\n",
    "        z=re.sub(r'\\[inaudible]', '', y)\n",
    "        doc=re.sub(r'\\[Music]', '', z)\n",
    "       \n",
    "        corpus.append(doc)\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oov(keys):\n",
    "    keys2=[]\n",
    "    for key in keys:\n",
    "        if key in model.vocab:\n",
    "            keys2.append(key)\n",
    "    x=len(keys)-len(keys2)\n",
    "    y=x*(sum(list(map(model.word_vec,keys2)))/len(keys2))\n",
    "    vector=sum(list(map(model.word_vec,keys2)))+y\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_space(url_list):\n",
    "    docs=make_corpus(url_list)\n",
    "    vectors_list=[]\n",
    "    for i in range(len(docs)):\n",
    "        clean_doc=remove_stopwords(docs[i])\n",
    "        keys=keywords(clean_doc, words=5,pos_filter=('NN','NNS','NNPS','NNP',),lemmatize=True, split=True)\n",
    "    \n",
    "        try:\n",
    "            vector=sum(list(map(model.word_vec,keys)))\n",
    "        except KeyError:\n",
    "            vector=oov(keys)\n",
    "                \n",
    "        vectors_list.append(vector)\n",
    "   \n",
    "    return (sum(vectors_list)/len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywords_to_vect(keys):\n",
    "\n",
    "    try:\n",
    "        vector=sum(list(map(model.word_vec,keys)))\n",
    "    except KeyError:\n",
    "        vector=oov(keys)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_analyze(url,topic_dict):\n",
    "    doc=make_corpus([url])\n",
    "    x=get_topic_space([url])\n",
    "    topic_dict_vectors={}\n",
    "    analysis={}\n",
    "\n",
    "    for key, value in topic_dict.items():\n",
    "        topic_dict_vectors[f'{key}']=keywords_to_vect(value)\n",
    "    for key, value in topic_dict_vectors.items():\n",
    "        analysis[f'{key}']=str(round(cos_sim(x,value),3))\n",
    "    \n",
    "    clean_doc=remove_stopwords(doc[0])\n",
    "    keys=keywords(clean_doc,words=5,pos_filter=('NN','NNS','NNPS','NNP',),lemmatize=True,split=True)\n",
    "   \n",
    "    summary=summarize(doc[0],word_count=50,split=True)\n",
    "    return {'Keys':keys, 'Summary':summary,'Analysis':analysis}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "glove_file = datapath('/Users/andrewportal/Downloads/glove/glove.6B.100d.txt')\n",
    "tmp_file = get_tmpfile(\"glove_word2vec.txt\")\n",
    "\n",
    "# call glove2word2vec script\n",
    "# default way (through CLI): python -m gensim.scripts.glove2word2vec --input <glove_file> --output <w2v_file>\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_keys=['border','wall','immigration','funding','promise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mueller_keys=['probe','investigation','election', \"collusion\",\"interference\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stormy_keys=['affair', 'president','lawyer','payment','campaign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBA_keys=['conference', 'basketball','league','championship','playoffs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "poke_keys=['pokemon','pikachu','nintendo','videogame','fun']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp={}\n",
    "tp['Border Wall']=['border','wall','immigration','funding','promise']\n",
    "tp['Mueller']=['probe','investigation','election', \"collusion\",\"interference\"]\n",
    "tp[\"stormy\"]=['affair', 'president','lawyer','payment','campaign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Keys': ['family', 'trump', 'premise', 'civility', 'bar'],\n",
       " 'Summary': ['Putting up silly things like this all right so it really unbecoming of Congress.',\n",
       "  'I protected Mr trump for ten years.',\n",
       "  'Unlike my calling for trump that has a thousand followers hes got over sixty million people.',\n",
       "  'Have you ever seen Mr trump personally threaten people with the physical harm  No. One he would use others.'],\n",
       " 'Analysis': {'Border Wall': '0.468', 'Mueller': '0.457', 'stormy': '0.591'}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_analyze('https://www.youtube.com/watch?v=BbHLPBJvSOc&t=3759s',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_string = ('jump,run, bite,play,game')\n",
    "keys_clean = key_string.replace(' ','')\n",
    "keys = keys_clean.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jump', 'run', 'bite', 'play', 'game']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
