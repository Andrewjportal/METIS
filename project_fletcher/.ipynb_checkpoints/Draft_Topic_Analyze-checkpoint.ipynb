{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xml.etree import ElementTree as ET\n",
    "import bleach\n",
    "import re\n",
    "import pattern3\n",
    "\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "from gensim.summarization import keywords\n",
    "from gensim.summarization.summarizer import summarize\n",
    "\n",
    "# sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(url):\n",
    "    path=url\n",
    "    yt = YouTube(path)\n",
    "    caption = yt.captions.get_by_language_code('en')\n",
    "    xml=caption.xml_captions\n",
    "    root = ET.fromstring(xml)\n",
    "    #gets the transcripts\n",
    "    doc=''\n",
    "    for child in root:\n",
    "        doc=doc+\" \"+(child.text)\n",
    "    return doc.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corpus(url_list):\n",
    "    corpus=[]\n",
    "    for url in url_list:\n",
    "        x=bleach.clean(get_transcript(url), tags=[], attributes={}, styles=[], strip=True)\n",
    "        y=re.sub(r'&#39;', '', x)\n",
    "        doc=re.sub(r'\\[Music]', '', y)\n",
    "        corpus.append(doc)\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_space(url_list):\n",
    "    docs=make_corpus(url_list)\n",
    "    vectors_list=[]\n",
    "    for i in range(len(docs)):\n",
    "        keys=keywords(docs[i], words=5,lemmatize='True').split('\\n')\n",
    "        vector=sum(list(map(model.word_vec,keys)))\n",
    "        vectors_list.append(vector)\n",
    "   \n",
    "    return (sum(vectors_list)/len(docs))\n",
    "                     \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "glove_file = datapath('/Users/andrewportal/Downloads/glove/glove.6B.50d.txt')\n",
    "tmp_file = get_tmpfile(\"glove_word2vec.txt\")\n",
    "\n",
    "# call glove2word2vec script\n",
    "# default way (through CLI): python -m gensim.scripts.glove2word2vec --input <glove_file> --output <w2v_file>\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3blueonebrown, gameranx review of metro exdus, vice news yemen\n",
    "url_list=('https://www.youtube.com/watch?v=jsYwFizhncE',\n",
    "        'https://www.youtube.com/watch?v=fdaVySF_-FQ&feature=youtu.be',\n",
    "        'https://www.youtube.com/watch?v=RWOPlynTcmk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=make_corpus(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coalitions', 'like', 'theyre', 'yeah', 'fight']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords(data[2], words=5,lemmatize='True').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coalitions', 0.18399542158735666),\n",
       " ('like', 0.14072211620294292),\n",
       " ('theyre', 0.13782141995374134),\n",
       " ('yeah', 0.13605972327836172),\n",
       " ('fight', 0.11932284361949205),\n",
       " ('millions', 0.1094493060259919),\n",
       " ('man', 0.10911786356583644),\n",
       " ('think', 0.10858279217361419),\n",
       " ('yemen', 0.107649421208776),\n",
       " ('coming', 0.10509094815675935),\n",
       " ('people', 0.10482108111922271),\n",
       " ('area', 0.10090488987500289),\n",
       " ('houthis', 0.10081812965667268),\n",
       " ('little', 0.09851658792241659),\n",
       " ('allah', 0.08974182495052808)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords(data[2],words=15,pos_filter=('NN'),lemmatize=True,scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coalitions', 0.18399542158735757),\n",
       " ('like', 0.14072211620294267),\n",
       " ('theyre', 0.13782141995374106),\n",
       " ('yeah', 0.1360597232783616),\n",
       " ('fight', 0.1193228436194926),\n",
       " ('millions', 0.10944930602599186),\n",
       " ('man', 0.10911786356583658),\n",
       " ('think', 0.10858279217361415),\n",
       " ('yemen', 0.10764942120877619),\n",
       " ('coming', 0.10509094815675951)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords(data[2], words=10,scores='True', lemmatize='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If that first block has a mass which is some power of 100 times the mass of the second, for example 1,000,000 times as much, an insanely surprising fact popped out: The total number of collisions, including those between the second mass and the wall, has the same starting digits as pi.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(data[0], ratio=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "glove_file = datapath('/Users/andrewportal/Downloads/glove/glove.6B.50d.txt')\n",
    "tmp_file = get_tmpfile(\"glove_word2vec.txt\")\n",
    "\n",
    "# call glove2word2vec script\n",
    "# default way (through CLI): python -m gensim.scripts.glove2word2vec --input <glove_file> --output <w2v_file>\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9893647516162923"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_similarity(['obama', 'president'], ['clinton', 'president'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=keywords(data[0], words=5,lemmatize='True').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=keywords(data[1], words=5,lemmatize='True').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=keywords(data[2], words=5,lemmatize='True').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1=list(map(model.word_vec,x))\n",
    "vector2=list(map(model.word_vec,y))\n",
    "vector3=list(map(model.word_vec,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=(sum(vector1))\n",
    "test2=(sum(vector2))\n",
    "test3=(sum(vector3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list=(test1,test2,test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecl=sum(test_list)/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.4131131e-01, -7.3579568e-01,  1.0339093e+00,  8.2039875e-01,\n",
       "        5.3618300e-01,  6.2923334e-03, -5.4832882e-01,  2.6783338e-02,\n",
       "       -4.4474664e-01,  1.5703840e+00, -1.6001169e-01,  5.9797329e-01,\n",
       "       -2.6063004e+00,  1.9161171e+00, -7.6865354e-03,  5.4009300e-01,\n",
       "        1.5315199e+00,  1.1847132e+00, -1.2932111e+00, -2.0422976e+00,\n",
       "       -6.0389662e-01, -9.2646670e-01,  5.3122962e-01,  8.8260442e-01,\n",
       "        6.4226031e-01, -4.2216668e+00, -1.5525804e+00,  6.0834354e-01,\n",
       "        2.5877457e+00, -1.8794533e+00,  9.7607508e+00,  2.4767368e+00,\n",
       "       -8.1350070e-01, -7.9928875e-01, -1.1277546e+00, -5.8675331e-01,\n",
       "       -4.2665729e-01, -3.0934092e-01,  4.7505701e-01, -1.3624351e-01,\n",
       "       -1.8324178e+00, -8.3093101e-01, -1.7135878e+00,  1.2964234e+00,\n",
       "        4.0663481e-03,  1.1034474e+00,  1.9586933e-01, -2.7896002e-01,\n",
       "        7.9566002e-02,  1.3572668e+00], dtype=float32)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a,b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(vecl,check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "check=get_topic_space(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.load('en_core_web_sm')\n",
    "from spacy.lang.en import English, STOP_WORDS\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_new = \" \".join([word for word in data[0] if word not in STOP_WORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
