{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "import pandas as pd\n",
    "import numpy as pd\n",
    "from xml.etree import ElementTree as ET\n",
    "import bleach\n",
    "import re\n",
    "\n",
    "\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "\n",
    "# sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# logging for gensim (set to INFO)\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(url):\n",
    "    path=url\n",
    "    yt = YouTube(path)\n",
    "    caption = yt.captions.get_by_language_code('en')\n",
    "    xml=caption.xml_captions\n",
    "    root = ET.fromstring(xml)\n",
    "    #gets the transcripts\n",
    "    doc=''\n",
    "    for child in root:\n",
    "        doc=doc+\" \"+(child.text)\n",
    "    return doc.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corpus(url_list):\n",
    "    corpus=[]\n",
    "    for url in url_list:\n",
    "        x=bleach.clean(get_transcript(url), tags=[], attributes={}, styles=[], strip=True)\n",
    "        y=re.sub(r'&#39;', '', x)\n",
    "        doc=re.sub(r'\\[Music]', '', y)\n",
    "        corpus.append(doc)\n",
    "    \n",
    "    return corpus\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3blueonebrown, gameranx review of metro exdus, vice news yemen\n",
    "url_list=('https://www.youtube.com/watch?v=jsYwFizhncE',\n",
    "        'https://www.youtube.com/watch?v=fdaVySF_-FQ&feature=youtu.be',\n",
    "        'https://www.youtube.com/watch?v=RWOPlynTcmk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=make_corpus(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='\\\\b[a-z][a-z]+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a CountVectorizer for parsing/counting words\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2),  \n",
    "                                   stop_words='english', token_pattern=\"\\\\b[a-z][a-z]+\\\\b\")\n",
    "\n",
    "count_vectorizer.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the term-document matrix\n",
    "# Transpose it so the terms are the rows\n",
    "doc_word = count_vectorizer.transform(data).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrix of counts to a gensim corpus\n",
    "corpus = matutils.Sparse2Corpus(doc_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3967, 3)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = dict((v, k) for k, v in count_vectorizer.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3967"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-26 16:41:40,104 : INFO : using symmetric alpha at 0.25\n",
      "2019-02-26 16:41:40,106 : INFO : using symmetric eta at 0.25\n",
      "2019-02-26 16:41:40,109 : INFO : using serial LDA version on this node\n",
      "2019-02-26 16:41:40,113 : INFO : running online (multi-pass) LDA training, 4 topics, 5 passes over the supplied corpus of 3 documents, updating model once every 3 documents, evaluating perplexity every 3 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2019-02-26 16:41:40,114 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-02-26 16:41:40,210 : INFO : -10.354 per-word bound, 1309.2 perplexity estimate based on a held-out corpus of 3 documents with 5525 words\n",
      "2019-02-26 16:41:40,211 : INFO : PROGRESS: pass 0, at document #3/3\n",
      "2019-02-26 16:41:40,231 : INFO : topic #0 (0.250): 0.004*\"like\" + 0.004*\"just\" + 0.003*\"circle\" + 0.003*\"game\" + 0.003*\"mass\" + 0.002*\"know\" + 0.002*\"little\" + 0.002*\"think\" + 0.002*\"theta\" + 0.002*\"angle\"\n",
      "2019-02-26 16:41:40,234 : INFO : topic #1 (0.250): 0.004*\"just\" + 0.004*\"like\" + 0.004*\"game\" + 0.002*\"really\" + 0.002*\"know\" + 0.002*\"think\" + 0.002*\"people\" + 0.002*\"im\" + 0.002*\"big\" + 0.002*\"theta\"\n",
      "2019-02-26 16:41:40,238 : INFO : topic #2 (0.250): 0.004*\"like\" + 0.003*\"just\" + 0.003*\"theta\" + 0.003*\"think\" + 0.003*\"circle\" + 0.002*\"pi\" + 0.002*\"little\" + 0.002*\"people\" + 0.002*\"value\" + 0.002*\"energy\"\n",
      "2019-02-26 16:41:40,239 : INFO : topic #3 (0.250): 0.005*\"just\" + 0.003*\"like\" + 0.003*\"game\" + 0.003*\"know\" + 0.003*\"think\" + 0.002*\"people\" + 0.002*\"im\" + 0.002*\"youre\" + 0.002*\"theres\" + 0.002*\"really\"\n",
      "2019-02-26 16:41:40,241 : INFO : topic diff=0.864876, rho=1.000000\n",
      "2019-02-26 16:41:40,315 : INFO : -9.336 per-word bound, 646.2 perplexity estimate based on a held-out corpus of 3 documents with 5525 words\n",
      "2019-02-26 16:41:40,316 : INFO : PROGRESS: pass 1, at document #3/3\n",
      "2019-02-26 16:41:40,333 : INFO : topic #0 (0.250): 0.005*\"circle\" + 0.005*\"theta\" + 0.004*\"mass\" + 0.004*\"pi\" + 0.004*\"block\" + 0.004*\"angle\" + 0.003*\"momentum\" + 0.003*\"value\" + 0.003*\"like\" + 0.003*\"energy\"\n",
      "2019-02-26 16:41:40,336 : INFO : topic #1 (0.250): 0.007*\"game\" + 0.006*\"like\" + 0.004*\"just\" + 0.004*\"really\" + 0.004*\"know\" + 0.004*\"metro\" + 0.003*\"games\" + 0.003*\"people\" + 0.003*\"time\" + 0.002*\"big\"\n",
      "2019-02-26 16:41:40,342 : INFO : topic #2 (0.250): 0.003*\"like\" + 0.002*\"just\" + 0.002*\"theta\" + 0.002*\"think\" + 0.002*\"circle\" + 0.002*\"pi\" + 0.001*\"little\" + 0.001*\"people\" + 0.001*\"value\" + 0.001*\"energy\"\n",
      "2019-02-26 16:41:40,346 : INFO : topic #3 (0.250): 0.007*\"just\" + 0.004*\"think\" + 0.003*\"like\" + 0.003*\"people\" + 0.003*\"coalition\" + 0.003*\"im\" + 0.003*\"know\" + 0.002*\"yeah\" + 0.002*\"fighting\" + 0.002*\"data\"\n",
      "2019-02-26 16:41:40,347 : INFO : topic diff=0.854586, rho=0.577350\n",
      "2019-02-26 16:41:40,424 : INFO : -8.551 per-word bound, 375.0 perplexity estimate based on a held-out corpus of 3 documents with 5525 words\n",
      "2019-02-26 16:41:40,427 : INFO : PROGRESS: pass 2, at document #3/3\n",
      "2019-02-26 16:41:40,440 : INFO : topic #0 (0.250): 0.006*\"theta\" + 0.006*\"circle\" + 0.005*\"mass\" + 0.005*\"pi\" + 0.004*\"block\" + 0.004*\"angle\" + 0.004*\"momentum\" + 0.004*\"value\" + 0.004*\"energy\" + 0.003*\"blocks\"\n",
      "2019-02-26 16:41:40,443 : INFO : topic #1 (0.250): 0.008*\"game\" + 0.007*\"like\" + 0.005*\"really\" + 0.004*\"just\" + 0.004*\"metro\" + 0.004*\"know\" + 0.004*\"games\" + 0.003*\"people\" + 0.003*\"time\" + 0.003*\"stuff\"\n",
      "2019-02-26 16:41:40,444 : INFO : topic #2 (0.250): 0.002*\"like\" + 0.001*\"just\" + 0.001*\"theta\" + 0.001*\"think\" + 0.001*\"circle\" + 0.001*\"pi\" + 0.001*\"little\" + 0.001*\"people\" + 0.001*\"value\" + 0.001*\"energy\"\n",
      "2019-02-26 16:41:40,446 : INFO : topic #3 (0.250): 0.007*\"just\" + 0.005*\"think\" + 0.003*\"like\" + 0.003*\"coalition\" + 0.003*\"people\" + 0.003*\"im\" + 0.002*\"yeah\" + 0.002*\"fighting\" + 0.002*\"know\" + 0.002*\"data\"\n",
      "2019-02-26 16:41:40,448 : INFO : topic diff=0.412470, rho=0.500000\n",
      "2019-02-26 16:41:40,518 : INFO : -8.404 per-word bound, 338.6 perplexity estimate based on a held-out corpus of 3 documents with 5525 words\n",
      "2019-02-26 16:41:40,519 : INFO : PROGRESS: pass 3, at document #3/3\n",
      "2019-02-26 16:41:40,528 : INFO : topic #0 (0.250): 0.006*\"theta\" + 0.006*\"circle\" + 0.005*\"mass\" + 0.005*\"pi\" + 0.005*\"block\" + 0.004*\"angle\" + 0.004*\"momentum\" + 0.004*\"value\" + 0.004*\"energy\" + 0.004*\"blocks\"\n",
      "2019-02-26 16:41:40,529 : INFO : topic #1 (0.250): 0.009*\"game\" + 0.007*\"like\" + 0.005*\"really\" + 0.005*\"metro\" + 0.004*\"just\" + 0.004*\"know\" + 0.004*\"games\" + 0.003*\"people\" + 0.003*\"time\" + 0.003*\"stuff\"\n",
      "2019-02-26 16:41:40,530 : INFO : topic #2 (0.250): 0.001*\"like\" + 0.001*\"just\" + 0.001*\"theta\" + 0.001*\"think\" + 0.001*\"circle\" + 0.001*\"pi\" + 0.001*\"little\" + 0.001*\"people\" + 0.001*\"value\" + 0.001*\"energy\"\n",
      "2019-02-26 16:41:40,533 : INFO : topic #3 (0.250): 0.007*\"just\" + 0.005*\"think\" + 0.003*\"coalition\" + 0.003*\"like\" + 0.003*\"people\" + 0.003*\"im\" + 0.003*\"yeah\" + 0.003*\"fighting\" + 0.003*\"data\" + 0.002*\"know\"\n",
      "2019-02-26 16:41:40,534 : INFO : topic diff=0.229509, rho=0.447214\n",
      "2019-02-26 16:41:40,594 : INFO : -8.359 per-word bound, 328.3 perplexity estimate based on a held-out corpus of 3 documents with 5525 words\n",
      "2019-02-26 16:41:40,595 : INFO : PROGRESS: pass 4, at document #3/3\n",
      "2019-02-26 16:41:40,603 : INFO : topic #0 (0.250): 0.006*\"theta\" + 0.006*\"circle\" + 0.005*\"mass\" + 0.005*\"pi\" + 0.005*\"block\" + 0.004*\"angle\" + 0.004*\"momentum\" + 0.004*\"value\" + 0.004*\"energy\" + 0.004*\"blocks\"\n",
      "2019-02-26 16:41:40,605 : INFO : topic #1 (0.250): 0.009*\"game\" + 0.007*\"like\" + 0.005*\"really\" + 0.005*\"metro\" + 0.004*\"just\" + 0.004*\"know\" + 0.004*\"games\" + 0.003*\"people\" + 0.003*\"time\" + 0.003*\"stuff\"\n",
      "2019-02-26 16:41:40,607 : INFO : topic #2 (0.250): 0.001*\"like\" + 0.001*\"just\" + 0.001*\"theta\" + 0.001*\"think\" + 0.001*\"circle\" + 0.001*\"pi\" + 0.001*\"little\" + 0.001*\"people\" + 0.000*\"value\" + 0.000*\"energy\"\n",
      "2019-02-26 16:41:40,608 : INFO : topic #3 (0.250): 0.007*\"just\" + 0.005*\"think\" + 0.003*\"coalition\" + 0.003*\"like\" + 0.003*\"people\" + 0.003*\"im\" + 0.003*\"yeah\" + 0.003*\"fighting\" + 0.003*\"data\" + 0.002*\"know\"\n",
      "2019-02-26 16:41:40,610 : INFO : topic diff=0.132862, rho=0.408248\n"
     ]
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus=corpus, num_topics=4, id2word=id2word, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-26 16:41:40,798 : INFO : topic #0 (0.250): 0.006*\"theta\" + 0.006*\"circle\" + 0.005*\"mass\" + 0.005*\"pi\" + 0.005*\"block\" + 0.004*\"angle\" + 0.004*\"momentum\" + 0.004*\"value\" + 0.004*\"energy\" + 0.004*\"blocks\"\n",
      "2019-02-26 16:41:40,800 : INFO : topic #1 (0.250): 0.009*\"game\" + 0.007*\"like\" + 0.005*\"really\" + 0.005*\"metro\" + 0.004*\"just\" + 0.004*\"know\" + 0.004*\"games\" + 0.003*\"people\" + 0.003*\"time\" + 0.003*\"stuff\"\n",
      "2019-02-26 16:41:40,802 : INFO : topic #2 (0.250): 0.001*\"like\" + 0.001*\"just\" + 0.001*\"theta\" + 0.001*\"think\" + 0.001*\"circle\" + 0.001*\"pi\" + 0.001*\"little\" + 0.001*\"people\" + 0.000*\"value\" + 0.000*\"energy\"\n",
      "2019-02-26 16:41:40,805 : INFO : topic #3 (0.250): 0.007*\"just\" + 0.005*\"think\" + 0.003*\"coalition\" + 0.003*\"like\" + 0.003*\"people\" + 0.003*\"im\" + 0.003*\"yeah\" + 0.003*\"fighting\" + 0.003*\"data\" + 0.002*\"know\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"theta\" + 0.006*\"circle\" + 0.005*\"mass\" + 0.005*\"pi\" + 0.005*\"block\" + 0.004*\"angle\" + 0.004*\"momentum\" + 0.004*\"value\" + 0.004*\"energy\" + 0.004*\"blocks\"'),\n",
       " (1,\n",
       "  '0.009*\"game\" + 0.007*\"like\" + 0.005*\"really\" + 0.005*\"metro\" + 0.004*\"just\" + 0.004*\"know\" + 0.004*\"games\" + 0.003*\"people\" + 0.003*\"time\" + 0.003*\"stuff\"'),\n",
       " (2,\n",
       "  '0.001*\"like\" + 0.001*\"just\" + 0.001*\"theta\" + 0.001*\"think\" + 0.001*\"circle\" + 0.001*\"pi\" + 0.001*\"little\" + 0.001*\"people\" + 0.000*\"value\" + 0.000*\"energy\"'),\n",
       " (3,\n",
       "  '0.007*\"just\" + 0.005*\"think\" + 0.003*\"coalition\" + 0.003*\"like\" + 0.003*\"people\" + 0.003*\"im\" + 0.003*\"yeah\" + 0.003*\"fighting\" + 0.003*\"data\" + 0.002*\"know\"')]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x1a1e822940>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the docs from the word space to the topic space (like \"transform\" in sklearn)\n",
    "lda_corpus = lda[corpus]\n",
    "lda_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the documents' topic vectors in a list so we can take a peak\n",
    "lda_docs = [doc for doc in lda_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.9996092)], [(1, 0.9995075)], [(3, 0.9996346)]]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the document vectors in the topic space for the first 5 documents\n",
    "lda_docs[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.9996092)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
